GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/10
Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/10
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/10
Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/10
Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/10
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/10
Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/10
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/10
Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/10
Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/10
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 10 processes
----------------------------------------------------------------------------------------------------

You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name      | Type        | Params
------------------------------------------
0 | esm_model | ESM2        | 2.8 B 
1 | proj      | Sequential  | 5.1 K 
2 | auroc     | BinaryAUROC | 0     
------------------------------------------
793 M     Trainable params
2.0 B     Non-trainable params
2.8 B     Total params
11,356.043Total estimated model params size (MB)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 8440768.0 ON g095 CANCELLED AT 2023-06-12T12:06:14 ***
slurmstepd: error: *** JOB 8440768 ON g095 CANCELLED AT 2023-06-12T12:06:14 ***
