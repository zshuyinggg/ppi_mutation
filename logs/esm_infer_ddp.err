GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name      | Type            | Params
----------------------------------------------
0 | esm_model | ESM2            | 33.5 M
1 | proj      | Sequential      | 1.4 K 
2 | auroc     | MulticlassAUROC | 0     
----------------------------------------------
22.4 M    Trainable params
11.1 M    Non-trainable params
33.5 M    Total params
134.011   Total estimated model params size (MB)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/lightning/pytorch/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/lightning/pytorch/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
[rank: 0] Metric val_loss improved. New best score: 0.822
[rank: 3] Metric val_loss improved. New best score: 0.822
[rank: 2] Metric val_loss improved. New best score: 0.822
[rank: 1] Metric val_loss improved. New best score: 0.822
[rank: 0] Metric val_loss improved by 0.025 >= min_delta = 0.0. New best score: 0.797
[rank: 1] Metric val_loss improved by 0.025 >= min_delta = 0.0. New best score: 0.797
[rank: 3] Metric val_loss improved by 0.025 >= min_delta = 0.0. New best score: 0.797
[rank: 2] Metric val_loss improved by 0.025 >= min_delta = 0.0. New best score: 0.797
[rank: 1] Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.778
[rank: 0] Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.778
[rank: 2] Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.778
[rank: 3] Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.778
[rank: 3] Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.777
[rank: 0] Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.777
[rank: 1] Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.777
[rank: 2] Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.777
[rank: 1] Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.771
[rank: 0] Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.771
[rank: 3] Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.771
[rank: 2] Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.771
[rank: 0] Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.767
[rank: 3] Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.767
[rank: 1] Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.767
[rank: 2] Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.767
[rank: 0] Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.763
[rank: 3] Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.763
[rank: 2] Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.763
[rank: 1] Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.763
[rank: 1] Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.760
[rank: 3] Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.760
[rank: 0] Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.760
[rank: 2] Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.760
[rank: 0] Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.759
[rank: 3] Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.759
[rank: 2] Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.759
[rank: 1] Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.759
[rank: 2] Monitored metric val_loss did not improve in the last 5 records. Best score: 0.759. Signaling Trainer to stop.
[rank: 0] Monitored metric val_loss did not improve in the last 5 records. Best score: 0.759. Signaling Trainer to stop.
[rank: 3] Monitored metric val_loss did not improve in the last 5 records. Best score: 0.759. Signaling Trainer to stop.
[rank: 1] Monitored metric val_loss did not improve in the last 5 records. Best score: 0.759. Signaling Trainer to stop.
You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /scratch/user/zshuying/ppi_mutation/logs/esm_finetune_ddp/esm2_t12_35M_UR50D/lr4-05_unfreeze8/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name      | Type            | Params
----------------------------------------------
0 | esm_model | ESM2            | 33.5 M
1 | proj      | Sequential      | 1.4 K 
2 | auroc     | MulticlassAUROC | 0     
----------------------------------------------
22.4 M    Trainable params
11.1 M    Non-trainable params
33.5 M    Total params
134.011   Total estimated model params size (MB)
You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name      | Type            | Params
----------------------------------------------
0 | esm_model | ESM2            | 33.5 M
1 | proj      | Sequential      | 1.4 K 
2 | auroc     | MulticlassAUROC | 0     
----------------------------------------------
22.4 M    Trainable params
11.1 M    Non-trainable params
33.5 M    Total params
134.011   Total estimated model params size (MB)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/lightning/pytorch/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
