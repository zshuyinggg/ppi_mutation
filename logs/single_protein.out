Lmod has detected the following error: The following module(s) are unknown:
"Python/3.9.15"

Please check the spelling, capitalization or version number. Also try "module
spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "Python/3.9.15"

Also make sure that all modulefiles written in TCL start with the string
#%Module



Python 3.9.15
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_49', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:05:16 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:05:17 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:05:17 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:11<07:03, 11.77s/it]Evaluation:   5%|▌         | 2/37 [00:11<02:54,  4.97s/it]Evaluation:   8%|▊         | 3/37 [00:12<01:34,  2.78s/it]Evaluation:  14%|█▎        | 5/37 [00:12<00:40,  1.27s/it]Evaluation:  16%|█▌        | 6/37 [00:12<00:29,  1.07it/s]Evaluation:  19%|█▉        | 7/37 [00:12<00:23,  1.27it/s]Evaluation:  24%|██▍       | 9/37 [00:13<00:13,  2.04it/s]Evaluation:  27%|██▋       | 10/37 [00:13<00:11,  2.35it/s]Evaluation:  30%|██▉       | 11/37 [00:13<00:08,  2.90it/s]Evaluation:  35%|███▌      | 13/37 [00:14<00:10,  2.21it/s]Evaluation:  38%|███▊      | 14/37 [00:14<00:09,  2.47it/s]Evaluation:  43%|████▎     | 16/37 [00:15<00:05,  3.79it/s]Evaluation:  51%|█████▏    | 19/37 [00:15<00:02,  6.32it/s]Evaluation:  57%|█████▋    | 21/37 [00:15<00:02,  7.93it/s]Evaluation:  62%|██████▏   | 23/37 [00:15<00:02,  6.48it/s]Evaluation:  68%|██████▊   | 25/37 [00:15<00:01,  7.13it/s]Evaluation:  73%|███████▎  | 27/37 [00:16<00:01,  8.24it/s]Evaluation:  78%|███████▊  | 29/37 [00:16<00:01,  6.85it/s]Evaluation:  81%|████████  | 30/37 [00:16<00:01,  6.98it/s]Evaluation:  84%|████████▍ | 31/37 [00:16<00:00,  6.31it/s]Evaluation:  92%|█████████▏| 34/37 [00:17<00:00,  5.88it/s]Evaluation:  95%|█████████▍| 35/37 [00:17<00:00,  5.79it/s]Evaluation:  97%|█████████▋| 36/37 [00:17<00:00,  6.12it/s]Evaluation: 100%|██████████| 37/37 [00:17<00:00,  6.61it/s]Evaluation: 100%|██████████| 37/37 [00:17<00:00,  2.07it/s]
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation temporarily disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_72', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:07:36 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:07:36 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:07:36 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<01:59,  3.22s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.11it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  2.03it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:12,  2.49it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:14,  2.20it/s]Evaluation:  21%|██        | 8/38 [00:04<00:12,  2.46it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:08,  3.24it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.60it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.70it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.31it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.80it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  6.89it/s]Evaluation:  53%|█████▎    | 20/38 [00:06<00:02,  8.52it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.61it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  7.25it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  6.98it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.81it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  8.33it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.45it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.32it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:02,  3.49it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.03it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  4.73it/s]Evaluation:  92%|█████████▏| 35/38 [00:08<00:00,  5.09it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.51it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.51it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.07it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_38', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:07:56 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:07:56 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:07:56 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:11,  3.54s/it]Evaluation:   5%|▌         | 2/38 [00:03<00:55,  1.53s/it]Evaluation:  11%|█         | 4/38 [00:03<00:20,  1.64it/s]Evaluation:  16%|█▌        | 6/38 [00:04<00:13,  2.34it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:15,  2.05it/s]Evaluation:  21%|██        | 8/38 [00:05<00:12,  2.33it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:10,  2.73it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:06,  3.84it/s]Evaluation:  34%|███▍      | 13/38 [00:06<00:06,  4.14it/s]Evaluation:  39%|███▉      | 15/38 [00:06<00:04,  5.20it/s]Evaluation:  42%|████▏     | 16/38 [00:06<00:03,  5.74it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:03,  6.08it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.38it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  6.92it/s]Evaluation:  53%|█████▎    | 20/38 [00:06<00:02,  7.44it/s]Evaluation:  58%|█████▊    | 22/38 [00:07<00:02,  6.97it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  6.72it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  6.27it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:01,  6.03it/s]Evaluation:  74%|███████▎  | 28/38 [00:08<00:01,  7.49it/s]Evaluation:  76%|███████▋  | 29/38 [00:08<00:01,  6.80it/s]Evaluation:  79%|███████▉  | 30/38 [00:08<00:01,  6.60it/s]Evaluation:  82%|████████▏ | 31/38 [00:09<00:02,  3.04it/s]Evaluation:  84%|████████▍ | 32/38 [00:09<00:01,  3.57it/s]Evaluation:  89%|████████▉ | 34/38 [00:09<00:00,  4.12it/s]Evaluation:  92%|█████████▏| 35/38 [00:09<00:00,  4.76it/s]Evaluation:  97%|█████████▋| 37/38 [00:10<00:00,  4.83it/s]Evaluation: 100%|██████████| 38/38 [00:10<00:00,  4.86it/s]Evaluation: 100%|██████████| 38/38 [00:10<00:00,  3.60it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_28', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:08:18 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:08:18 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:08:18 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:03,  3.43s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:54,  1.55s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:31,  1.08it/s]Evaluation:  11%|█         | 4/37 [00:04<00:20,  1.61it/s]Evaluation:  14%|█▎        | 5/37 [00:04<00:13,  2.31it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  3.07it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.96it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:07,  3.65it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:06,  4.18it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  4.25it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.53it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.35it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:09,  2.66it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:07,  3.04it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.82it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  8.06it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  8.89it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:01,  7.21it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.04it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.81it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  6.75it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  6.44it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.55it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:00,  6.02it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  8.34it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.73it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  4.78it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.27it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.81it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_14', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:08:38 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:08:38 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:08:38 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:04,  3.45s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:54,  1.56s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:32,  1.06it/s]Evaluation:  11%|█         | 4/37 [00:04<00:20,  1.59it/s]Evaluation:  14%|█▎        | 5/37 [00:04<00:14,  2.27it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  3.01it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.89it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.59it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:06,  4.07it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  4.16it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.43it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.26it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:08,  2.85it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:07,  3.21it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  5.08it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  8.51it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  9.42it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:01,  7.56it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.25it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  8.07it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  6.82it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  6.98it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.37it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.90it/s]Evaluation:  92%|█████████▏| 34/37 [00:09<00:00,  5.82it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  5.97it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  6.07it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.10it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.88it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_15', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:08:59 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:08:59 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:08:59 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<01:59,  3.23s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.12it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  2.03it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:12,  2.51it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.26it/s]Evaluation:  21%|██        | 8/38 [00:04<00:11,  2.68it/s]Evaluation:  24%|██▎       | 9/38 [00:04<00:08,  3.37it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:08,  3.18it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.97it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.00it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.97it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.86it/s]Evaluation:  50%|█████     | 19/38 [00:05<00:02,  7.71it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  9.18it/s]Evaluation:  61%|██████    | 23/38 [00:06<00:01,  8.99it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  7.11it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.88it/s]Evaluation:  74%|███████▎  | 28/38 [00:06<00:01,  8.41it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.78it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.56it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.64it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.34it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.33it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  6.72it/s]Evaluation:  97%|█████████▋| 37/38 [00:08<00:00,  5.78it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  5.69it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.22it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_62', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:09:19 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:09:19 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:09:19 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:09,  3.59s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:57,  1.64s/it]Evaluation:   8%|▊         | 3/37 [00:04<00:34,  1.00s/it]Evaluation:  11%|█         | 4/37 [00:04<00:21,  1.55it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:11,  2.77it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:12,  2.50it/s]Evaluation:  24%|██▍       | 9/37 [00:05<00:07,  3.57it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.40it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  3.90it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.64it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:08,  2.79it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:07,  3.02it/s]Evaluation:  41%|████      | 15/37 [00:06<00:06,  3.64it/s]Evaluation:  49%|████▊     | 18/37 [00:07<00:02,  6.83it/s]Evaluation:  57%|█████▋    | 21/37 [00:07<00:01,  9.56it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:02,  6.54it/s]Evaluation:  68%|██████▊   | 25/37 [00:08<00:01,  6.59it/s]Evaluation:  73%|███████▎  | 27/37 [00:08<00:01,  6.90it/s]Evaluation:  76%|███████▌  | 28/37 [00:08<00:01,  5.57it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  5.84it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  5.60it/s]Evaluation:  84%|████████▍ | 31/37 [00:09<00:01,  5.21it/s]Evaluation:  92%|█████████▏| 34/37 [00:09<00:00,  4.73it/s]Evaluation:  95%|█████████▍| 35/37 [00:10<00:00,  5.03it/s]Evaluation:  97%|█████████▋| 36/37 [00:10<00:00,  5.26it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  5.39it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  3.56it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_40', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:09:40 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:09:40 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:09:40 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:59,  3.33s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:53,  1.52s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:31,  1.07it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.64it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.92it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.53it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.62it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.47it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  3.99it/s]Evaluation:  32%|███▏      | 12/37 [00:07<00:15,  1.62it/s]
Traceback (most recent call last):
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/main.py", line 331, in <module>
    run_eval()
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/main.py", line 272, in run_eval
    return training.run_eval(**eval_args)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 1251, in run_eval
    metrics_to_save, outputs_to_save = run_eval_epoch(valid_loader, runner, metrics, metric_functions,
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 550, in run_eval_epoch
    loss, metrics, outputs = runner.forward(batch, return_outputs=True) # type: ignore
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 106, in forward
    outputs = self.model(**batch)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 597, in forward
    encoder_outputs = self.encoder(embedding_output,
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 482, in forward
    layer_outputs = layer_module(hidden_states, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 420, in forward
    attention_outputs = self.attention(hidden_states, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 370, in forward
    self_outputs = self.self(input_tensor, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 289, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
RuntimeError: CUDA out of memory. Tried to allocate 3.64 GiB (GPU 0; 39.45 GiB total capacity; 34.16 GiB already allocated; 67.50 MiB free; 38.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: g034: task 0: Exited with exit code 1
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_19', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:09:57 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:09:57 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:09:57 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:58,  3.30s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:53,  1.52s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:31,  1.06it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.64it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.92it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.68it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.74it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.76it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  4.04it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.73it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:07,  3.09it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:06,  3.31it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.28it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  8.82it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  9.91it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:01,  7.74it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.27it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  8.15it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  6.45it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.49it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.88it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  7.49it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  5.22it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  5.31it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.26it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.76it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.91it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_46', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:10:18 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:10:18 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:10:18 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:03,  3.43s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:53,  1.54s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.10it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.64it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.92it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.73it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.34it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.98it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  4.22it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.92it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.78it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:10,  2.31it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:08,  2.75it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.45it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  7.66it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  9.36it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:02,  6.78it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.30it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.71it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  6.61it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.45it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:00,  6.29it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  8.34it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.88it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.37it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.93it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.84it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_68', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:10:38 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:10:38 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:10:38 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:59,  3.31s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:54,  1.55s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:32,  1.05it/s]Evaluation:  14%|█▎        | 5/37 [00:04<00:14,  2.20it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.54it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:08,  3.49it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:08,  3.19it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:07,  3.71it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:07,  3.07it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:07,  3.05it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.52it/s]Evaluation:  49%|████▊     | 18/37 [00:06<00:03,  6.01it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  8.65it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:02,  6.10it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  6.45it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.58it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  5.84it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.10it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.06it/s]Evaluation:  92%|█████████▏| 34/37 [00:09<00:00,  4.39it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.74it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.18it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  5.47it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  3.64it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_35', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:10:59 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:10:59 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:10:59 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:02,  3.41s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:53,  1.53s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.10it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.65it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.97it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.79it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.85it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  3.98it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.62it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.39it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:09,  2.59it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:08,  2.83it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.55it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  7.69it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  9.46it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:01,  7.08it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.57it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.97it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  6.96it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:00,  7.09it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:00,  6.20it/s]Evaluation:  92%|█████████▏| 34/37 [00:09<00:00,  5.36it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  5.74it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  6.03it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.61it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.93it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_26', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:11:19 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:11:19 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:11:19 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<01:55,  3.12s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:30,  1.14it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  2.02it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.39it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.30it/s]Evaluation:  21%|██        | 8/38 [00:04<00:11,  2.51it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:08,  3.14it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:06,  4.20it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.48it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  5.92it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.38it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:03,  6.25it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.28it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  6.90it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  8.73it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  6.36it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:02,  5.75it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  5.25it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.27it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  6.92it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.02it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  6.28it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.85it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.29it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.05it/s]Evaluation:  92%|█████████▏| 35/38 [00:09<00:00,  5.71it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.44it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.26it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  3.94it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_37', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:11:40 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:11:40 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:11:40 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:00,  3.35s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.51s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.11it/s]Evaluation:  11%|█         | 4/37 [00:03<00:19,  1.66it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.96it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.65it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.27it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.85it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  4.05it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.74it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.15it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:07,  3.36it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:06,  3.62it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.74it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:01,  9.46it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 11.33it/s]Evaluation:  62%|██████▏   | 23/37 [00:06<00:01,  8.06it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  8.39it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  9.44it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  7.42it/s]Evaluation:  81%|████████  | 30/37 [00:07<00:00,  7.41it/s]Evaluation:  84%|████████▍ | 31/37 [00:07<00:00,  6.38it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  8.44it/s]Evaluation:  95%|█████████▍| 35/37 [00:08<00:00,  4.60it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.06it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.61it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  4.04it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_21', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:12:00 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:12:00 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:12:00 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:04,  3.47s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:54,  1.57s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:31,  1.06it/s]Evaluation:  11%|█         | 4/37 [00:04<00:20,  1.60it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.88it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.75it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.37it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.87it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.85it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  4.21it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.05it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:06,  3.74it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:06,  3.71it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.86it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:01,  9.49it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 11.32it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:01,  7.37it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.58it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.95it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  6.58it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.25it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.78it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  7.75it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.98it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.17it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.17it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.90it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_43', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:12:20 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:12:20 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:12:20 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:02,  3.31s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:32,  1.09it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  2.00it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:12,  2.47it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:12,  2.45it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.86it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:07,  3.54it/s]Evaluation:  32%|███▏      | 12/38 [00:04<00:05,  4.95it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.43it/s]Evaluation:  37%|███▋      | 14/38 [00:05<00:04,  5.80it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  7.30it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  7.89it/s]Evaluation:  53%|█████▎    | 20/38 [00:05<00:01,  9.43it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:01,  8.08it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  7.94it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  7.14it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  7.04it/s]Evaluation:  74%|███████▎  | 28/38 [00:06<00:01,  8.49it/s]Evaluation:  76%|███████▋  | 29/38 [00:06<00:01,  8.49it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.54it/s]Evaluation:  82%|████████▏ | 31/38 [00:07<00:01,  4.48it/s]Evaluation:  87%|████████▋ | 33/38 [00:07<00:00,  6.30it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.44it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  7.29it/s]Evaluation:  97%|█████████▋| 37/38 [00:08<00:00,  6.23it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  5.73it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  4.38it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_44', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:12:39 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:12:39 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:12:39 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:03,  3.34s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:32,  1.08it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.97it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.45it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:12,  2.42it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.88it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:07,  3.64it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  5.05it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.37it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.45it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.93it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.36it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  7.42it/s]Evaluation:  50%|█████     | 19/38 [00:05<00:02,  7.95it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  8.61it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.75it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  8.31it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  7.78it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.84it/s]Evaluation:  74%|███████▎  | 28/38 [00:06<00:01,  8.43it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  8.24it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.98it/s]Evaluation:  82%|████████▏ | 31/38 [00:07<00:01,  3.90it/s]Evaluation:  84%|████████▍ | 32/38 [00:07<00:01,  4.48it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.21it/s]Evaluation:  92%|█████████▏| 35/38 [00:08<00:00,  5.84it/s]Evaluation:  97%|█████████▋| 37/38 [00:08<00:00,  6.25it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  5.83it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  4.28it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_33', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:12:59 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:12:59 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:12:59 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:07,  3.55s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:56,  1.61s/it]Evaluation:   8%|▊         | 3/37 [00:04<00:33,  1.01it/s]Evaluation:  11%|█         | 4/37 [00:04<00:21,  1.56it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:11,  2.78it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.59it/s]Evaluation:  24%|██▍       | 9/37 [00:05<00:07,  3.63it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.74it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  4.01it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.69it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:10,  2.30it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:08,  2.64it/s]Evaluation:  43%|████▎     | 16/37 [00:07<00:05,  4.16it/s]Evaluation:  49%|████▊     | 18/37 [00:07<00:03,  5.72it/s]Evaluation:  54%|█████▍    | 20/37 [00:07<00:02,  7.59it/s]Evaluation:  59%|█████▉    | 22/37 [00:07<00:01,  8.66it/s]Evaluation:  65%|██████▍   | 24/37 [00:08<00:02,  5.90it/s]Evaluation:  70%|███████   | 26/37 [00:08<00:01,  7.21it/s]Evaluation:  76%|███████▌  | 28/37 [00:08<00:01,  6.13it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  6.27it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.33it/s]Evaluation:  84%|████████▍ | 31/37 [00:09<00:01,  5.46it/s]Evaluation:  89%|████████▉ | 33/37 [00:09<00:00,  7.50it/s]Evaluation:  92%|█████████▏| 34/37 [00:09<00:00,  5.16it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.92it/s]Evaluation:  97%|█████████▋| 36/37 [00:10<00:00,  5.05it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  5.52it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  3.60it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_65', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:13:20 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:13:20 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:13:20 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:02,  3.30s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:32,  1.09it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.96it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.43it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:14,  2.19it/s]Evaluation:  21%|██        | 8/38 [00:04<00:12,  2.47it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:09,  3.11it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:06,  4.21it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.57it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.13it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.66it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:03,  6.98it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.63it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  7.25it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  9.24it/s]Evaluation:  61%|██████    | 23/38 [00:06<00:01,  7.84it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  7.36it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  6.74it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:01,  6.48it/s]Evaluation:  71%|███████   | 27/38 [00:07<00:01,  6.65it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.86it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.63it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.62it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.30it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  4.91it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  6.53it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.63it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.10it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.01it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_70', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:13:40 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:13:40 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:13:40 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:08,  3.48s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:33,  1.05it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:17,  1.91it/s]Evaluation:  16%|█▌        | 6/38 [00:04<00:13,  2.36it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.32it/s]Evaluation:  21%|██        | 8/38 [00:04<00:11,  2.71it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:08,  3.40it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.87it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.19it/s]Evaluation:  37%|███▋      | 14/38 [00:05<00:04,  5.70it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  7.26it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.55it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  7.50it/s]Evaluation:  50%|█████     | 19/38 [00:05<00:02,  8.01it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  8.90it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.39it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  8.26it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  6.89it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.66it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  8.39it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  8.24it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.07it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.95it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.38it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.47it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  7.27it/s]Evaluation:  97%|█████████▋| 37/38 [00:08<00:00,  5.78it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.67it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.18it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_13', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:14:00 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:14:00 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:14:00 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:04,  3.36s/it]Evaluation:   5%|▌         | 2/38 [00:03<00:52,  1.44s/it]Evaluation:  11%|█         | 4/38 [00:03<00:19,  1.74it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:12,  2.49it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:12,  2.48it/s]Evaluation:  21%|██        | 8/38 [00:04<00:11,  2.65it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:08,  3.28it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.49it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.53it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  5.90it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.28it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:03,  6.61it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.16it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  6.73it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:02,  8.39it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  6.31it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  5.89it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  5.69it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.26it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  6.88it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.04it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  6.38it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.81it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.51it/s]Evaluation:  89%|████████▉ | 34/38 [00:09<00:00,  4.95it/s]Evaluation:  92%|█████████▏| 35/38 [00:09<00:00,  5.60it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.46it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.29it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  3.90it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_47', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:14:21 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:14:21 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:14:21 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:07,  3.45s/it]Evaluation:   5%|▌         | 2/38 [00:03<00:53,  1.48s/it]Evaluation:  11%|█         | 4/38 [00:03<00:19,  1.71it/s]Evaluation:  16%|█▌        | 6/38 [00:04<00:13,  2.45it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:12,  2.51it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.78it/s]Evaluation:  24%|██▎       | 9/38 [00:04<00:08,  3.38it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:08,  3.24it/s]Evaluation:  29%|██▉       | 11/38 [00:05<00:06,  4.01it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.81it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.72it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.38it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.67it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:03,  6.82it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.17it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  6.71it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:02,  8.38it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  6.97it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  6.26it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  6.02it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.97it/s]Evaluation:  71%|███████   | 27/38 [00:07<00:01,  6.09it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.24it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.06it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.94it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.57it/s]Evaluation:  89%|████████▉ | 34/38 [00:09<00:00,  5.22it/s]Evaluation:  92%|█████████▏| 35/38 [00:09<00:00,  5.81it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  6.11it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.50it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  3.92it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_63', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:14:41 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:14:41 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:14:41 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:04,  3.47s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:55,  1.59s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:33,  1.02it/s]Evaluation:  11%|█         | 4/37 [00:04<00:20,  1.57it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:11,  2.81it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:12,  2.49it/s]Evaluation:  24%|██▍       | 9/37 [00:05<00:07,  3.53it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.41it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  3.90it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.59it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:10,  2.22it/s]Evaluation:  38%|███▊      | 14/37 [00:07<00:09,  2.43it/s]Evaluation:  43%|████▎     | 16/37 [00:07<00:05,  3.89it/s]Evaluation:  51%|█████▏    | 19/37 [00:07<00:02,  6.56it/s]Evaluation:  57%|█████▋    | 21/37 [00:07<00:01,  8.13it/s]Evaluation:  62%|██████▏   | 23/37 [00:08<00:02,  5.81it/s]Evaluation:  68%|██████▊   | 25/37 [00:08<00:02,  5.92it/s]Evaluation:  73%|███████▎  | 27/37 [00:08<00:01,  6.89it/s]Evaluation:  76%|███████▌  | 28/37 [00:08<00:01,  5.45it/s]Evaluation:  78%|███████▊  | 29/37 [00:09<00:01,  5.46it/s]Evaluation:  81%|████████  | 30/37 [00:09<00:01,  5.63it/s]Evaluation:  84%|████████▍ | 31/37 [00:09<00:01,  5.22it/s]Evaluation:  89%|████████▉ | 33/37 [00:09<00:00,  6.92it/s]Evaluation:  92%|█████████▏| 34/37 [00:10<00:00,  4.37it/s]Evaluation:  95%|█████████▍| 35/37 [00:10<00:00,  4.52it/s]Evaluation:  97%|█████████▋| 36/37 [00:10<00:00,  4.93it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  5.61it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  3.49it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_71', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:15:03 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:15:03 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:15:03 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<01:58,  3.20s/it]Evaluation:   5%|▌         | 2/38 [00:03<00:49,  1.38s/it]Evaluation:  11%|█         | 4/38 [00:03<00:18,  1.80it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:12,  2.52it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:12,  2.43it/s]Evaluation:  21%|██        | 8/38 [00:04<00:11,  2.54it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:08,  3.17it/s]Evaluation:  29%|██▉       | 11/38 [00:05<00:07,  3.65it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.64it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  5.86it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  5.78it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:03,  6.08it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.24it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  6.66it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:02,  7.52it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  6.35it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  5.40it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  5.04it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.06it/s]Evaluation:  71%|███████   | 27/38 [00:07<00:01,  5.72it/s]Evaluation:  76%|███████▋  | 29/38 [00:08<00:01,  6.31it/s]Evaluation:  79%|███████▉  | 30/38 [00:08<00:01,  6.27it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.78it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.39it/s]Evaluation:  89%|████████▉ | 34/38 [00:09<00:00,  5.10it/s]Evaluation:  92%|█████████▏| 35/38 [00:09<00:00,  5.20it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.51it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.03it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  3.81it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_1', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:15:24 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:15:24 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:15:24 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:02,  3.41s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:54,  1.54s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:31,  1.08it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.63it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.92it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.82it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.40it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.87it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.83it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.46it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.95it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:07,  3.15it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:07,  3.22it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  5.00it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  8.21it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  9.88it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:01,  7.09it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.45it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.96it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  6.60it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  6.87it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.64it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.99it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  5.68it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  5.88it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  6.11it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.63it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.96it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_24', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:15:44 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:15:44 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:15:44 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:11,  3.55s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:34,  1.02it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:17,  1.84it/s]Evaluation:  16%|█▌        | 6/38 [00:04<00:14,  2.23it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.25it/s]Evaluation:  21%|██        | 8/38 [00:04<00:12,  2.45it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:09,  3.05it/s]Evaluation:  29%|██▉       | 11/38 [00:05<00:07,  3.65it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:06,  4.12it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.51it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.14it/s]Evaluation:  42%|████▏     | 16/38 [00:06<00:03,  6.57it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:03,  6.23it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.32it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  6.91it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  8.58it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  6.39it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  5.99it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  5.77it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.25it/s]Evaluation:  71%|███████   | 27/38 [00:07<00:01,  5.95it/s]Evaluation:  76%|███████▋  | 29/38 [00:08<00:01,  7.15it/s]Evaluation:  79%|███████▉  | 30/38 [00:08<00:01,  6.86it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  4.10it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.77it/s]Evaluation:  89%|████████▉ | 34/38 [00:09<00:00,  5.10it/s]Evaluation:  92%|█████████▏| 35/38 [00:09<00:00,  5.64it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.44it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.31it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  3.80it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_29', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:16:05 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:16:05 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:16:05 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/36 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/36 [00:03<01:58,  3.39s/it]Evaluation:   6%|▌         | 2/36 [00:03<00:50,  1.48s/it]Evaluation:  11%|█         | 4/36 [00:04<00:24,  1.32it/s]Evaluation:  17%|█▋        | 6/36 [00:04<00:14,  2.12it/s]Evaluation:  22%|██▏       | 8/36 [00:04<00:09,  2.90it/s]Evaluation:  25%|██▌       | 9/36 [00:04<00:07,  3.39it/s]Evaluation:  28%|██▊       | 10/36 [00:05<00:06,  3.81it/s]Evaluation:  36%|███▌      | 13/36 [00:05<00:03,  6.10it/s]Evaluation:  39%|███▉      | 14/36 [00:05<00:03,  6.24it/s]Evaluation:  42%|████▏     | 15/36 [00:05<00:04,  4.58it/s]Evaluation:  44%|████▍     | 16/36 [00:05<00:03,  5.23it/s]Evaluation:  47%|████▋     | 17/36 [00:06<00:04,  4.74it/s]Evaluation:  53%|█████▎    | 19/36 [00:06<00:02,  5.78it/s]Evaluation:  58%|█████▊    | 21/36 [00:06<00:02,  6.82it/s]Evaluation:  64%|██████▍   | 23/36 [00:06<00:01,  7.91it/s]Evaluation:  67%|██████▋   | 24/36 [00:07<00:01,  6.70it/s]Evaluation:  69%|██████▉   | 25/36 [00:07<00:02,  5.14it/s]Evaluation:  72%|███████▏  | 26/36 [00:07<00:01,  5.27it/s]Evaluation:  78%|███████▊  | 28/36 [00:07<00:01,  5.64it/s]Evaluation:  83%|████████▎ | 30/36 [00:08<00:01,  4.96it/s]Evaluation:  89%|████████▉ | 32/36 [00:08<00:00,  5.82it/s]Evaluation:  94%|█████████▍| 34/36 [00:08<00:00,  6.51it/s]Evaluation:  97%|█████████▋| 35/36 [00:09<00:00,  5.93it/s]Evaluation: 100%|██████████| 36/36 [00:09<00:00,  5.85it/s]Evaluation: 100%|██████████| 36/36 [00:09<00:00,  3.85it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_6', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:16:25 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:16:25 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:16:25 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/36 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/36 [00:03<01:57,  3.36s/it]Evaluation:   6%|▌         | 2/36 [00:03<00:49,  1.46s/it]Evaluation:  11%|█         | 4/36 [00:04<00:23,  1.37it/s]Evaluation:  17%|█▋        | 6/36 [00:04<00:13,  2.20it/s]Evaluation:  22%|██▏       | 8/36 [00:04<00:09,  3.04it/s]Evaluation:  28%|██▊       | 10/36 [00:04<00:06,  3.99it/s]Evaluation:  36%|███▌      | 13/36 [00:05<00:03,  6.15it/s]Evaluation:  42%|████▏     | 15/36 [00:05<00:05,  4.01it/s]Evaluation:  47%|████▋     | 17/36 [00:06<00:04,  4.37it/s]Evaluation:  53%|█████▎    | 19/36 [00:06<00:03,  5.21it/s]Evaluation:  58%|█████▊    | 21/36 [00:06<00:02,  6.54it/s]Evaluation:  64%|██████▍   | 23/36 [00:06<00:01,  7.37it/s]Evaluation:  69%|██████▉   | 25/36 [00:07<00:02,  5.45it/s]Evaluation:  72%|███████▏  | 26/36 [00:07<00:01,  5.63it/s]Evaluation:  78%|███████▊  | 28/36 [00:07<00:01,  6.45it/s]Evaluation:  83%|████████▎ | 30/36 [00:08<00:01,  5.66it/s]Evaluation:  89%|████████▉ | 32/36 [00:08<00:00,  6.98it/s]Evaluation:  94%|█████████▍| 34/36 [00:08<00:00,  7.77it/s]Evaluation:  97%|█████████▋| 35/36 [00:08<00:00,  6.65it/s]Evaluation: 100%|██████████| 36/36 [00:08<00:00,  7.03it/s]Evaluation: 100%|██████████| 36/36 [00:08<00:00,  4.02it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_16', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:16:45 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:16:45 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:16:45 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:00,  3.34s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.51s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.10it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.64it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.92it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.54it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.69it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.69it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  4.01it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.68it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:09,  2.60it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:08,  2.87it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.53it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  7.09it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  8.70it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:02,  6.57it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  6.41it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.24it/s]Evaluation:  76%|███████▌  | 28/37 [00:08<00:01,  5.51it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  5.85it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.05it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.71it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  7.41it/s]Evaluation:  92%|█████████▏| 34/37 [00:09<00:00,  3.65it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.16it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  4.70it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  5.43it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  3.66it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_64', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:17:06 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:17:06 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:17:06 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:00,  3.36s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.51s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.10it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.64it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.92it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.88it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.87it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  3.98it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.54it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.95it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:07,  3.39it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:06,  3.64it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.68it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:01,  9.35it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 11.21it/s]Evaluation:  62%|██████▏   | 23/37 [00:06<00:01,  8.23it/s]Evaluation:  68%|██████▊   | 25/37 [00:06<00:01,  8.38it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  9.21it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  7.38it/s]Evaluation:  81%|████████  | 30/37 [00:07<00:00,  7.41it/s]Evaluation:  84%|████████▍ | 31/37 [00:07<00:00,  6.98it/s]Evaluation:  89%|████████▉ | 33/37 [00:07<00:00,  8.49it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  5.15it/s]Evaluation:  95%|█████████▍| 35/37 [00:08<00:00,  5.15it/s]Evaluation:  97%|█████████▋| 36/37 [00:08<00:00,  5.55it/s]Evaluation: 100%|██████████| 37/37 [00:08<00:00,  6.15it/s]Evaluation: 100%|██████████| 37/37 [00:08<00:00,  4.13it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_2', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:17:25 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:17:25 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:17:25 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:00,  3.34s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.50s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.12it/s]Evaluation:  11%|█         | 4/37 [00:03<00:19,  1.66it/s]Evaluation:  14%|█▎        | 5/37 [00:03<00:13,  2.37it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:09,  3.14it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.98it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:07,  3.70it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:06,  4.28it/s]Evaluation:  27%|██▋       | 10/37 [00:04<00:05,  4.50it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  5.13it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.49it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:10,  2.23it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:08,  2.66it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.32it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  7.36it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  9.11it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:02,  6.99it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.19it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.54it/s]Evaluation:  76%|███████▌  | 28/37 [00:08<00:01,  6.46it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  6.65it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.18it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.89it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  8.28it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  5.30it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.61it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.18it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.87it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_17', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:17:46 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:17:46 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:17:46 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:06,  3.51s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:55,  1.59s/it]Evaluation:   8%|▊         | 3/37 [00:04<00:33,  1.02it/s]Evaluation:  11%|█         | 4/37 [00:04<00:21,  1.57it/s]Evaluation:  14%|█▎        | 5/37 [00:04<00:14,  2.24it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.95it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.55it/s]Evaluation:  24%|██▍       | 9/37 [00:05<00:07,  3.76it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.66it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  4.17it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.87it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:09,  2.47it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:08,  2.85it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.31it/s]Evaluation:  51%|█████▏    | 19/37 [00:07<00:02,  7.29it/s]Evaluation:  57%|█████▋    | 21/37 [00:07<00:01,  8.98it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:02,  6.36it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  6.69it/s]Evaluation:  73%|███████▎  | 27/37 [00:08<00:01,  7.54it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  5.96it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.07it/s]Evaluation:  84%|████████▍ | 31/37 [00:09<00:01,  5.31it/s]Evaluation:  89%|████████▉ | 33/37 [00:09<00:00,  7.24it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.78it/s]Evaluation:  97%|█████████▋| 36/37 [00:10<00:00,  5.01it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  5.48it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  3.62it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_66', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:18:08 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:18:08 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:18:08 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:01,  3.27s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.10it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.98it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:12,  2.47it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:12,  2.44it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.80it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:07,  3.55it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.92it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.32it/s]Evaluation:  37%|███▋      | 14/38 [00:05<00:04,  5.68it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  7.13it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.55it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  7.60it/s]Evaluation:  50%|█████     | 19/38 [00:05<00:02,  7.41it/s]Evaluation:  55%|█████▌    | 21/38 [00:05<00:01,  9.10it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.24it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  7.26it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:02,  6.31it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.26it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  7.96it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.32it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.36it/s]Evaluation:  82%|████████▏ | 31/38 [00:07<00:01,  4.43it/s]Evaluation:  84%|████████▍ | 32/38 [00:07<00:01,  4.88it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.75it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  7.57it/s]Evaluation:  97%|█████████▋| 37/38 [00:08<00:00,  5.87it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  5.69it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  4.27it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_59', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:18:27 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:18:27 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:18:27 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:58,  3.30s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.49s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.12it/s]Evaluation:  11%|█         | 4/37 [00:03<00:19,  1.67it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.96it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.94it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.55it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:06,  4.03it/s]Evaluation:  27%|██▋       | 10/37 [00:04<00:06,  4.17it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.81it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.19it/s]Evaluation:  32%|███▏      | 12/37 [00:06<00:12,  1.95it/s]
Traceback (most recent call last):
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/main.py", line 331, in <module>
    run_eval()
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/main.py", line 272, in run_eval
    return training.run_eval(**eval_args)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 1251, in run_eval
    metrics_to_save, outputs_to_save = run_eval_epoch(valid_loader, runner, metrics, metric_functions,
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 550, in run_eval_epoch
    loss, metrics, outputs = runner.forward(batch, return_outputs=True) # type: ignore
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 106, in forward
    outputs = self.model(**batch)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 597, in forward
    encoder_outputs = self.encoder(embedding_output,
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 482, in forward
    layer_outputs = layer_module(hidden_states, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 420, in forward
    attention_outputs = self.attention(hidden_states, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 370, in forward
    self_outputs = self.self(input_tensor, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 290, in forward
    attention_scores = attention_scores / math.sqrt(self.attention_head_size)
RuntimeError: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.45 GiB total capacity; 32.30 GiB already allocated; 5.51 GiB free; 32.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: g034: task 0: Exited with exit code 1
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_52', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:18:43 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:18:43 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:18:43 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:59,  3.33s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.51s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.10it/s]Evaluation:  11%|█         | 4/37 [00:03<00:19,  1.65it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.99it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.92it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.90it/s]Evaluation:  27%|██▋       | 10/37 [00:04<00:06,  3.96it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.48it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.92it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:05,  4.47it/s]Evaluation:  38%|███▊      | 14/37 [00:05<00:05,  4.57it/s]Evaluation:  43%|████▎     | 16/37 [00:05<00:03,  6.75it/s]Evaluation:  49%|████▊     | 18/37 [00:06<00:02,  8.66it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 11.68it/s]Evaluation:  62%|██████▏   | 23/37 [00:06<00:01,  8.42it/s]Evaluation:  68%|██████▊   | 25/37 [00:06<00:01,  7.94it/s]Evaluation:  73%|███████▎  | 27/37 [00:06<00:01,  9.08it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  7.13it/s]Evaluation:  81%|████████  | 30/37 [00:07<00:00,  7.18it/s]Evaluation:  84%|████████▍ | 31/37 [00:07<00:00,  6.58it/s]Evaluation:  89%|████████▉ | 33/37 [00:07<00:00,  8.62it/s]Evaluation:  95%|█████████▍| 35/37 [00:08<00:00,  5.37it/s]Evaluation:  97%|█████████▋| 36/37 [00:08<00:00,  5.35it/s]Evaluation: 100%|██████████| 37/37 [00:08<00:00,  5.82it/s]Evaluation: 100%|██████████| 37/37 [00:08<00:00,  4.20it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_25', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:19:03 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:19:03 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:19:03 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:01,  3.28s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.11it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.99it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.45it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:15,  1.97it/s]Evaluation:  21%|██        | 8/38 [00:04<00:13,  2.21it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:10,  2.56it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:06,  3.80it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:06,  4.16it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  5.81it/s]Evaluation:  42%|████▏     | 16/38 [00:06<00:03,  5.95it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:03,  6.46it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:02,  6.69it/s]Evaluation:  53%|█████▎    | 20/38 [00:06<00:02,  8.81it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.03it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  6.33it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  5.66it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.67it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  7.46it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.41it/s]Evaluation:  79%|███████▉  | 30/38 [00:08<00:01,  6.71it/s]Evaluation:  82%|████████▏ | 31/38 [00:09<00:03,  2.28it/s]Evaluation:  84%|████████▍ | 32/38 [00:09<00:02,  2.81it/s]Evaluation:  89%|████████▉ | 34/38 [00:09<00:01,  3.36it/s]Evaluation:  95%|█████████▍| 36/38 [00:10<00:00,  4.82it/s]Evaluation:  97%|█████████▋| 37/38 [00:10<00:00,  3.86it/s]Evaluation: 100%|██████████| 38/38 [00:10<00:00,  4.01it/s]Evaluation: 100%|██████████| 38/38 [00:10<00:00,  3.52it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_48', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:19:25 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:19:25 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:19:25 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:58,  3.30s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.51s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:31,  1.07it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.64it/s]Evaluation:  14%|█▎        | 5/37 [00:04<00:13,  2.34it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  3.09it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.67it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.81it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.60it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  4.15it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.86it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:05,  4.76it/s]Evaluation:  38%|███▊      | 14/37 [00:05<00:05,  4.27it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  6.29it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:01,  9.84it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 11.20it/s]Evaluation:  62%|██████▏   | 23/37 [00:06<00:01,  7.43it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.32it/s]Evaluation:  70%|███████   | 26/37 [00:07<00:01,  7.37it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.56it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  5.92it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  5.92it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.12it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.66it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  8.04it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  4.29it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.73it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  4.83it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.53it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.94it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_22', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:19:45 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:19:45 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:19:45 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:03,  3.33s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:32,  1.08it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.97it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.43it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.36it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.75it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:08,  3.41it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.83it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.16it/s]Evaluation:  37%|███▋      | 14/38 [00:05<00:04,  5.61it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  7.13it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.52it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  7.53it/s]Evaluation:  50%|█████     | 19/38 [00:05<00:02,  7.50it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  9.48it/s]Evaluation:  61%|██████    | 23/38 [00:06<00:01,  9.13it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:02,  5.39it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:02,  5.47it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.64it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  7.02it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.21it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.24it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.67it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.33it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  4.94it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  6.73it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.71it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.66it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.11it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_39', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:20:06 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:20:06 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:20:06 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:00,  3.34s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.50s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.12it/s]Evaluation:  11%|█         | 4/37 [00:03<00:19,  1.68it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  3.02it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.79it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.84it/s]Evaluation:  27%|██▋       | 10/37 [00:04<00:06,  4.02it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.59it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:08,  2.90it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:07,  3.21it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.81it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  7.79it/s]Evaluation:  59%|█████▉    | 22/37 [00:06<00:01,  9.20it/s]Evaluation:  65%|██████▍   | 24/37 [00:07<00:01,  7.04it/s]Evaluation:  70%|███████   | 26/37 [00:07<00:01,  8.56it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  7.04it/s]Evaluation:  81%|████████  | 30/37 [00:07<00:00,  7.45it/s]Evaluation:  86%|████████▋ | 32/37 [00:08<00:00,  7.40it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  5.19it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  5.50it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.88it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.46it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.98it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_5', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:20:26 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:20:26 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:20:26 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:59,  3.33s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.51s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.10it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.63it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.89it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.67it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.68it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.75it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  3.98it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.63it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:06,  3.56it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:06,  3.63it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.58it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  8.89it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 10.31it/s]Evaluation:  62%|██████▏   | 23/37 [00:06<00:01,  7.34it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.42it/s]Evaluation:  70%|███████   | 26/37 [00:07<00:01,  7.52it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.67it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  6.32it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  6.57it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.17it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.71it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  8.07it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  4.41it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.71it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.01it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.02it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.89it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_7', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:20:46 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:20:46 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:20:46 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:01,  3.37s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.51s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.11it/s]Evaluation:  14%|█▎        | 5/37 [00:03<00:14,  2.18it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:11,  2.80it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.90it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.92it/s]Evaluation:  27%|██▋       | 10/37 [00:04<00:06,  3.99it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.51it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.28it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:08,  2.88it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:07,  3.09it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.89it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  8.19it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  9.87it/s]Evaluation:  62%|██████▏   | 23/37 [00:06<00:01,  7.61it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.97it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  8.77it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  7.16it/s]Evaluation:  81%|████████  | 30/37 [00:07<00:00,  7.21it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:00,  6.69it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  8.23it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  5.18it/s]Evaluation:  95%|█████████▍| 35/37 [00:08<00:00,  5.59it/s]Evaluation:  97%|█████████▋| 36/37 [00:08<00:00,  5.58it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.20it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  4.05it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_61', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:21:06 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:21:06 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:21:06 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:02,  3.40s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:54,  1.55s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:32,  1.05it/s]Evaluation:  11%|█         | 4/37 [00:04<00:20,  1.62it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.87it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.71it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.78it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.85it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  4.14it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.84it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:09,  2.48it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:08,  2.81it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.40it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  7.01it/s]Evaluation:  57%|█████▋    | 21/37 [00:07<00:01,  8.37it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:02,  6.94it/s]Evaluation:  65%|██████▍   | 24/37 [00:07<00:02,  6.18it/s]Evaluation:  70%|███████   | 26/37 [00:07<00:01,  7.36it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.53it/s]Evaluation:  76%|███████▌  | 28/37 [00:08<00:01,  5.58it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  5.96it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.05it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.58it/s]Evaluation:  89%|████████▉ | 33/37 [00:09<00:00,  7.18it/s]Evaluation:  92%|█████████▏| 34/37 [00:09<00:00,  4.78it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.75it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.12it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.64it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.72it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_42', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:21:27 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:21:27 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:21:27 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:11,  3.55s/it]Evaluation:   5%|▌         | 2/38 [00:03<00:54,  1.52s/it]Evaluation:  11%|█         | 4/38 [00:03<00:20,  1.65it/s]Evaluation:  16%|█▌        | 6/38 [00:04<00:13,  2.36it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:14,  2.07it/s]Evaluation:  21%|██        | 8/38 [00:05<00:12,  2.35it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:09,  2.81it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:06,  4.00it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.39it/s]Evaluation:  39%|███▉      | 15/38 [00:06<00:03,  5.89it/s]Evaluation:  42%|████▏     | 16/38 [00:06<00:03,  5.88it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:03,  6.38it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.46it/s]Evaluation:  53%|█████▎    | 20/38 [00:06<00:02,  8.36it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:02,  8.09it/s]Evaluation:  58%|█████▊    | 22/38 [00:07<00:02,  6.57it/s]Evaluation:  63%|██████▎   | 24/38 [00:08<00:04,  3.49it/s]Evaluation:  66%|██████▌   | 25/38 [00:08<00:03,  3.83it/s]Evaluation:  68%|██████▊   | 26/38 [00:08<00:02,  4.16it/s]Evaluation:  71%|███████   | 27/38 [00:08<00:02,  4.69it/s]Evaluation:  76%|███████▋  | 29/38 [00:08<00:01,  6.19it/s]Evaluation:  79%|███████▉  | 30/38 [00:08<00:01,  6.39it/s]Evaluation:  82%|████████▏ | 31/38 [00:09<00:02,  2.92it/s]Evaluation:  84%|████████▍ | 32/38 [00:09<00:01,  3.36it/s]Evaluation:  89%|████████▉ | 34/38 [00:10<00:00,  4.20it/s]Evaluation:  92%|█████████▏| 35/38 [00:10<00:00,  4.85it/s]Evaluation:  97%|█████████▋| 37/38 [00:10<00:00,  4.68it/s]Evaluation: 100%|██████████| 38/38 [00:10<00:00,  4.71it/s]Evaluation: 100%|██████████| 38/38 [00:11<00:00,  3.45it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_9', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:21:49 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:21:49 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:21:49 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:00,  3.34s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.51s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:31,  1.09it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.63it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.91it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.82it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.43it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.92it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  4.01it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.60it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.03it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:06,  3.74it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:06,  3.73it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.81it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:01,  9.45it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 11.12it/s]Evaluation:  62%|██████▏   | 23/37 [00:06<00:01,  7.57it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.56it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.85it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  6.51it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  6.74it/s]Evaluation:  81%|████████  | 30/37 [00:07<00:01,  6.77it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.67it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  6.02it/s]Evaluation:  95%|█████████▍| 35/37 [00:08<00:00,  5.79it/s]Evaluation:  97%|█████████▋| 36/37 [00:08<00:00,  5.96it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.52it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  4.06it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_69', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:22:09 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:22:09 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:22:09 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<01:57,  3.18s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.13it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  2.02it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.42it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.38it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.73it/s]Evaluation:  24%|██▎       | 9/38 [00:04<00:08,  3.40it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:08,  3.28it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.98it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.00it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.79it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  7.11it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.39it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  6.72it/s]Evaluation:  53%|█████▎    | 20/38 [00:05<00:02,  8.66it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.48it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:02,  6.27it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:02,  6.00it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.97it/s]Evaluation:  71%|███████   | 27/38 [00:07<00:01,  6.15it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.33it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.23it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  4.03it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.64it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  4.94it/s]Evaluation:  92%|█████████▏| 35/38 [00:08<00:00,  5.49it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.66it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.11it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.05it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_56', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:22:30 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:22:30 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:22:30 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<01:59,  3.23s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:30,  1.13it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  2.05it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:12,  2.56it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:12,  2.40it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.73it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:08,  3.38it/s]Evaluation:  32%|███▏      | 12/38 [00:04<00:05,  4.86it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.29it/s]Evaluation:  37%|███▋      | 14/38 [00:05<00:04,  5.83it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:02,  7.50it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  8.10it/s]Evaluation:  53%|█████▎    | 20/38 [00:05<00:01,  9.83it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:01,  8.34it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  8.19it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  7.03it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.81it/s]Evaluation:  74%|███████▎  | 28/38 [00:06<00:01,  8.58it/s]Evaluation:  76%|███████▋  | 29/38 [00:06<00:01,  8.77it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:00,  8.54it/s]Evaluation:  82%|████████▏ | 31/38 [00:07<00:01,  4.27it/s]Evaluation:  87%|████████▋ | 33/38 [00:07<00:00,  6.19it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.20it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  7.18it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  5.55it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  4.37it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_20', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:22:49 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:22:49 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:22:49 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:01,  3.38s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:53,  1.52s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.10it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.64it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.92it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.78it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.34it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.83it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  3.90it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.40it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.82it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:08,  2.87it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:06,  3.34it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.35it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  8.70it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 10.56it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:01,  7.55it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.39it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  8.35it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  7.13it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.68it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:00,  6.23it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  8.24it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.75it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.14it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.33it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.91it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_45', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:23:09 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:23:09 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:23:09 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:02,  3.32s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:32,  1.09it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.96it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.40it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:15,  1.98it/s]Evaluation:  21%|██        | 8/38 [00:04<00:13,  2.20it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:10,  2.71it/s]Evaluation:  29%|██▉       | 11/38 [00:05<00:08,  3.22it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.30it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  5.77it/s]Evaluation:  42%|████▏     | 16/38 [00:06<00:03,  5.79it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:03,  6.34it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.47it/s]Evaluation:  53%|█████▎    | 20/38 [00:06<00:02,  8.33it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  8.61it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  6.49it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  6.92it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  6.40it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.74it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  7.50it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.45it/s]Evaluation:  79%|███████▉  | 30/38 [00:08<00:01,  6.65it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:02,  3.03it/s]Evaluation:  84%|████████▍ | 32/38 [00:09<00:01,  3.68it/s]Evaluation:  89%|████████▉ | 34/38 [00:09<00:00,  4.62it/s]Evaluation:  95%|█████████▍| 36/38 [00:09<00:00,  5.89it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.24it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.31it/s]Evaluation: 100%|██████████| 38/38 [00:10<00:00,  3.80it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_32', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:23:30 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:23:30 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:23:30 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:00,  3.25s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.12it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  2.02it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:12,  2.49it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.35it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.76it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:08,  3.32it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.79it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.12it/s]Evaluation:  37%|███▋      | 14/38 [00:05<00:04,  5.64it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  7.28it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.70it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  7.59it/s]Evaluation:  53%|█████▎    | 20/38 [00:05<00:02,  8.62it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.73it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  7.15it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:02,  6.35it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.03it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  7.74it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.74it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  6.77it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:02,  2.97it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  3.60it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  4.51it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  5.89it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.21it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.23it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.05it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_74', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:23:51 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:23:51 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:23:51 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/59 [00:00<?, ?it/s]Evaluation:   2%|▏         | 1/59 [00:04<03:59,  4.13s/it]Evaluation:   3%|▎         | 2/59 [00:04<01:41,  1.77s/it]Evaluation:   7%|▋         | 4/59 [00:04<00:39,  1.39it/s]Evaluation:  10%|█         | 6/59 [00:04<00:21,  2.44it/s]Evaluation:  14%|█▎        | 8/59 [00:05<00:17,  2.90it/s]Evaluation:  17%|█▋        | 10/59 [00:05<00:12,  3.81it/s]Evaluation:  19%|█▊        | 11/59 [00:05<00:11,  4.32it/s]Evaluation:  20%|██        | 12/59 [00:05<00:10,  4.53it/s]Evaluation:  22%|██▏       | 13/59 [00:05<00:11,  4.02it/s]Evaluation:  24%|██▎       | 14/59 [00:06<00:11,  4.00it/s]Evaluation:  25%|██▌       | 15/59 [00:06<00:09,  4.47it/s]Evaluation:  29%|██▉       | 17/59 [00:06<00:08,  5.00it/s]Evaluation:  32%|███▏      | 19/59 [00:07<00:07,  5.04it/s]Evaluation:  34%|███▍      | 20/59 [00:07<00:07,  5.28it/s]Evaluation:  37%|███▋      | 22/59 [00:07<00:07,  4.90it/s]Evaluation:  41%|████      | 24/59 [00:07<00:05,  6.10it/s]Evaluation:  46%|████▌     | 27/59 [00:08<00:03,  8.75it/s]Evaluation:  49%|████▉     | 29/59 [00:08<00:03,  7.54it/s]Evaluation:  53%|█████▎    | 31/59 [00:08<00:03,  8.91it/s]Evaluation:  56%|█████▌    | 33/59 [00:08<00:03,  7.71it/s]Evaluation:  58%|█████▊    | 34/59 [00:09<00:03,  6.86it/s]Evaluation:  59%|█████▉    | 35/59 [00:09<00:03,  6.56it/s]Evaluation:  61%|██████    | 36/59 [00:09<00:03,  6.08it/s]Evaluation:  63%|██████▎   | 37/59 [00:09<00:03,  6.61it/s]Evaluation:  64%|██████▍   | 38/59 [00:09<00:03,  6.57it/s]Evaluation:  68%|██████▊   | 40/59 [00:09<00:02,  8.80it/s]Evaluation:  71%|███████   | 42/59 [00:10<00:02,  7.47it/s]Evaluation:  73%|███████▎  | 43/59 [00:10<00:02,  7.83it/s]Evaluation:  76%|███████▋  | 45/59 [00:10<00:01,  8.44it/s]Evaluation:  80%|███████▉  | 47/59 [00:11<00:03,  3.87it/s]Evaluation:  85%|████████▍ | 50/59 [00:11<00:01,  5.81it/s]Evaluation:  88%|████████▊ | 52/59 [00:12<00:01,  4.09it/s]Evaluation:  90%|████████▉ | 53/59 [00:12<00:01,  4.31it/s]Evaluation:  92%|█████████▏| 54/59 [00:13<00:01,  3.73it/s]Evaluation:  95%|█████████▍| 56/59 [00:13<00:00,  5.16it/s]Evaluation:  98%|█████████▊| 58/59 [00:13<00:00,  6.76it/s]Evaluation: 100%|██████████| 59/59 [00:13<00:00,  4.40it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_12', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:24:16 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:24:16 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:24:16 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:00,  3.26s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.10it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.99it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:12,  2.47it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.34it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.77it/s]Evaluation:  24%|██▎       | 9/38 [00:04<00:08,  3.42it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:08,  3.29it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.99it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.03it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.80it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  7.25it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.49it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  7.55it/s]Evaluation:  50%|█████     | 19/38 [00:05<00:02,  7.36it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  9.27it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.68it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  7.96it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  6.68it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.52it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  8.26it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.51it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.37it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.73it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.46it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.50it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  7.30it/s]Evaluation:  97%|█████████▋| 37/38 [00:08<00:00,  5.80it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.72it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.21it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_55', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:24:36 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:24:36 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:24:36 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:59,  3.33s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.51s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.10it/s]Evaluation:  11%|█         | 4/37 [00:03<00:19,  1.65it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.98it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.74it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.30it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.76it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.84it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.41it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.89it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:07,  3.09it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:06,  3.37it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.45it/s]Evaluation:  54%|█████▍    | 20/37 [00:06<00:01, 10.03it/s]Evaluation:  59%|█████▉    | 22/37 [00:06<00:01, 11.16it/s]Evaluation:  65%|██████▍   | 24/37 [00:07<00:01,  7.25it/s]Evaluation:  70%|███████   | 26/37 [00:07<00:01,  8.73it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  7.21it/s]Evaluation:  81%|████████  | 30/37 [00:07<00:00,  7.41it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:00,  6.53it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  5.63it/s]Evaluation:  95%|█████████▍| 35/37 [00:08<00:00,  5.87it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  6.20it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.71it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  4.05it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_27', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:24:56 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:24:56 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:24:56 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:00,  3.36s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:53,  1.53s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:31,  1.09it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.63it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.91it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.83it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.44it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.93it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  4.02it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.36it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.18it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:07,  3.38it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:06,  3.56it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.63it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:01,  9.30it/s]Evaluation:  59%|█████▉    | 22/37 [00:06<00:01, 10.42it/s]Evaluation:  65%|██████▍   | 24/37 [00:07<00:01,  7.61it/s]Evaluation:  70%|███████   | 26/37 [00:07<00:01,  8.36it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  7.16it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  7.44it/s]Evaluation:  81%|████████  | 30/37 [00:07<00:01,  6.89it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:00,  6.34it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  6.06it/s]Evaluation:  95%|█████████▍| 35/37 [00:08<00:00,  6.15it/s]Evaluation:  97%|█████████▋| 36/37 [00:08<00:00,  6.27it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.77it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  4.09it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_30', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:25:16 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:25:16 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:25:16 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:53,  3.16s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:50,  1.43s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:29,  1.16it/s]Evaluation:  11%|█         | 4/37 [00:03<00:19,  1.73it/s]Evaluation:  16%|█▌        | 6/37 [00:03<00:10,  3.10it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.82it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.89it/s]Evaluation:  27%|██▋       | 10/37 [00:04<00:06,  3.98it/s]Evaluation:  30%|██▉       | 11/37 [00:04<00:05,  4.59it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:11,  2.12it/s]
Traceback (most recent call last):
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/main.py", line 331, in <module>
    run_eval()
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/main.py", line 272, in run_eval
    return training.run_eval(**eval_args)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 1251, in run_eval
    metrics_to_save, outputs_to_save = run_eval_epoch(valid_loader, runner, metrics, metric_functions,
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 550, in run_eval_epoch
    loss, metrics, outputs = runner.forward(batch, return_outputs=True) # type: ignore
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 106, in forward
    outputs = self.model(**batch)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 597, in forward
    encoder_outputs = self.encoder(embedding_output,
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 482, in forward
    layer_outputs = layer_module(hidden_states, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 420, in forward
    attention_outputs = self.attention(hidden_states, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 370, in forward
    self_outputs = self.self(input_tensor, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 289, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
RuntimeError: CUDA out of memory. Tried to allocate 4.88 GiB (GPU 0; 39.45 GiB total capacity; 30.47 GiB already allocated; 2.26 GiB free; 35.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: g034: task 0: Exited with exit code 1
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_50', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:25:30 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:25:30 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:25:30 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:58,  3.29s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.51s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.11it/s]Evaluation:  11%|█         | 4/37 [00:03<00:19,  1.65it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.95it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:12,  2.41it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.51it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.61it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  3.93it/s]Evaluation:  32%|███▏      | 12/37 [00:06<00:12,  1.93it/s]
Traceback (most recent call last):
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/main.py", line 331, in <module>
    run_eval()
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/main.py", line 272, in run_eval
    return training.run_eval(**eval_args)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 1251, in run_eval
    metrics_to_save, outputs_to_save = run_eval_epoch(valid_loader, runner, metrics, metric_functions,
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 550, in run_eval_epoch
    loss, metrics, outputs = runner.forward(batch, return_outputs=True) # type: ignore
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 106, in forward
    outputs = self.model(**batch)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 597, in forward
    encoder_outputs = self.encoder(embedding_output,
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 482, in forward
    layer_outputs = layer_module(hidden_states, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 420, in forward
    attention_outputs = self.attention(hidden_states, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 370, in forward
    self_outputs = self.self(input_tensor, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 290, in forward
    attention_scores = attention_scores / math.sqrt(self.attention_head_size)
RuntimeError: CUDA out of memory. Tried to allocate 4.81 GiB (GPU 0; 39.45 GiB total capacity; 34.95 GiB already allocated; 2.04 GiB free; 36.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: g034: task 0: Exited with exit code 1
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_73', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:25:46 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:25:46 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:25:46 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:01,  3.29s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:32,  1.09it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.95it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.32it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.27it/s]Evaluation:  21%|██        | 8/38 [00:04<00:12,  2.50it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:08,  3.16it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:06,  4.33it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.58it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.20it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.64it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:03,  6.99it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.36it/s]Evaluation:  53%|█████▎    | 20/38 [00:06<00:02,  8.35it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  6.96it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  7.21it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:01,  6.62it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.86it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  7.40it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.50it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.08it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:02,  3.42it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.08it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  4.66it/s]Evaluation:  95%|█████████▍| 36/38 [00:09<00:00,  6.32it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.01it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.96it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  3.95it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_31', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:26:06 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:26:06 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:26:06 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:02,  3.30s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.09it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.99it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:12,  2.48it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:12,  2.40it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.82it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:07,  3.55it/s]Evaluation:  32%|███▏      | 12/38 [00:04<00:05,  5.01it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.39it/s]Evaluation:  37%|███▋      | 14/38 [00:05<00:04,  5.84it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:02,  7.35it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.70it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  7.71it/s]Evaluation:  53%|█████▎    | 20/38 [00:05<00:02,  8.70it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.92it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  7.73it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  6.82it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.74it/s]Evaluation:  74%|███████▎  | 28/38 [00:06<00:01,  8.48it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  8.44it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.47it/s]Evaluation:  82%|████████▏ | 31/38 [00:07<00:01,  3.96it/s]Evaluation:  84%|████████▍ | 32/38 [00:07<00:01,  4.41it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.46it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  7.25it/s]Evaluation:  97%|█████████▋| 37/38 [00:08<00:00,  5.85it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  5.83it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  4.29it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_41', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:26:26 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:26:26 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:26:26 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:04<02:30,  4.07s/it]Evaluation:   8%|▊         | 3/38 [00:04<00:38,  1.11s/it]Evaluation:  13%|█▎        | 5/38 [00:04<00:19,  1.66it/s]Evaluation:  16%|█▌        | 6/38 [00:04<00:15,  2.08it/s]Evaluation:  18%|█▊        | 7/38 [00:05<00:15,  2.05it/s]Evaluation:  21%|██        | 8/38 [00:05<00:12,  2.46it/s]Evaluation:  24%|██▎       | 9/38 [00:05<00:09,  3.13it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:09,  3.01it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.59it/s]Evaluation:  34%|███▍      | 13/38 [00:06<00:05,  4.70it/s]Evaluation:  39%|███▉      | 15/38 [00:06<00:03,  6.40it/s]Evaluation:  42%|████▏     | 16/38 [00:06<00:03,  6.88it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:02,  7.12it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:02,  7.04it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  6.86it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  8.68it/s]Evaluation:  58%|█████▊    | 22/38 [00:07<00:02,  7.32it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  5.44it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  5.56it/s]Evaluation:  68%|██████▊   | 26/38 [00:08<00:02,  5.72it/s]Evaluation:  71%|███████   | 27/38 [00:08<00:01,  6.11it/s]Evaluation:  76%|███████▋  | 29/38 [00:08<00:01,  7.46it/s]Evaluation:  79%|███████▉  | 30/38 [00:08<00:01,  7.30it/s]Evaluation:  82%|████████▏ | 31/38 [00:10<00:03,  1.93it/s]Evaluation:  84%|████████▍ | 32/38 [00:10<00:02,  2.34it/s]Evaluation:  89%|████████▉ | 34/38 [00:10<00:01,  3.27it/s]Evaluation:  92%|█████████▏| 35/38 [00:10<00:00,  3.86it/s]Evaluation:  97%|█████████▋| 37/38 [00:11<00:00,  4.36it/s]Evaluation: 100%|██████████| 38/38 [00:11<00:00,  4.63it/s]Evaluation: 100%|██████████| 38/38 [00:11<00:00,  3.37it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_23', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:26:48 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:26:48 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:26:48 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:06,  3.51s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:55,  1.58s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:32,  1.05it/s]Evaluation:  11%|█         | 4/37 [00:04<00:20,  1.57it/s]Evaluation:  14%|█▎        | 5/37 [00:04<00:14,  2.25it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  3.00it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.78it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.47it/s]Evaluation:  24%|██▍       | 9/37 [00:05<00:07,  3.98it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  3.96it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.42it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.30it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:07,  3.13it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:06,  3.47it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.46it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:01,  9.09it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 11.00it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:01,  7.44it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.35it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  8.43it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  6.66it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.71it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:00,  6.29it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  5.87it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  5.98it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  6.27it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.11it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.92it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_57', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:27:08 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:27:08 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:27:08 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:00,  3.25s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.10it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.98it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.38it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.38it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.77it/s]Evaluation:  24%|██▎       | 9/38 [00:04<00:08,  3.46it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:08,  3.36it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  5.00it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.93it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.46it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.94it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.28it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:03,  6.54it/s]Evaluation:  53%|█████▎    | 20/38 [00:06<00:02,  8.34it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  8.62it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.11it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  7.35it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  6.80it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.50it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  7.43it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.56it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.25it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  4.18it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.92it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.76it/s]Evaluation:  92%|█████████▏| 35/38 [00:08<00:00,  6.02it/s]Evaluation:  97%|█████████▋| 37/38 [00:08<00:00,  6.25it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  6.01it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.20it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_36', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:27:28 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:27:28 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:27:28 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:54,  3.18s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:50,  1.45s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:29,  1.16it/s]Evaluation:  11%|█         | 4/37 [00:03<00:19,  1.72it/s]Evaluation:  16%|█▌        | 6/37 [00:03<00:10,  3.07it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.78it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.39it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.97it/s]Evaluation:  27%|██▋       | 10/37 [00:04<00:06,  4.12it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.78it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.15it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:07,  3.28it/s]Evaluation:  38%|███▊      | 14/37 [00:05<00:06,  3.45it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.38it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  8.80it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 10.34it/s]Evaluation:  62%|██████▏   | 23/37 [00:06<00:01,  7.28it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.57it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.78it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  6.62it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  6.64it/s]Evaluation:  81%|████████  | 30/37 [00:07<00:01,  6.61it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.57it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  7.82it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  3.76it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  4.30it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  4.90it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.59it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.96it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_54', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:27:48 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:27:48 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:27:48 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:57,  3.27s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:51,  1.48s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.12it/s]Evaluation:  11%|█         | 4/37 [00:03<00:19,  1.66it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.96it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.72it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.34it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.91it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  3.96it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.63it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.06it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:06,  3.94it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:12,  1.85it/s]Evaluation:  41%|████      | 15/37 [00:07<00:11,  1.93it/s]Evaluation:  43%|████▎     | 16/37 [00:07<00:08,  2.41it/s]Evaluation:  49%|████▊     | 18/37 [00:07<00:04,  3.93it/s]Evaluation:  51%|█████▏    | 19/37 [00:07<00:03,  4.56it/s]Evaluation:  54%|█████▍    | 20/37 [00:07<00:03,  5.21it/s]Evaluation:  59%|█████▉    | 22/37 [00:08<00:02,  6.69it/s]Evaluation:  62%|██████▏   | 23/37 [00:08<00:03,  4.62it/s]Evaluation:  65%|██████▍   | 24/37 [00:08<00:02,  4.81it/s]Evaluation:  70%|███████   | 26/37 [00:08<00:01,  6.69it/s]Evaluation:  73%|███████▎  | 27/37 [00:09<00:01,  6.56it/s]Evaluation:  76%|███████▌  | 28/37 [00:09<00:01,  5.28it/s]Evaluation:  78%|███████▊  | 29/37 [00:09<00:01,  5.81it/s]Evaluation:  81%|████████  | 30/37 [00:09<00:01,  6.18it/s]Evaluation:  84%|████████▍ | 31/37 [00:09<00:01,  5.22it/s]Evaluation:  89%|████████▉ | 33/37 [00:09<00:00,  7.51it/s]Evaluation:  92%|█████████▏| 34/37 [00:10<00:00,  4.41it/s]Evaluation:  95%|█████████▍| 35/37 [00:10<00:00,  4.97it/s]Evaluation:  97%|█████████▋| 36/37 [00:10<00:00,  5.44it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  6.17it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  3.40it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_3', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:28:10 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:28:10 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:28:10 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:12,  3.58s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:34,  1.01it/s]Evaluation:  13%|█▎        | 5/38 [00:04<00:18,  1.82it/s]Evaluation:  16%|█▌        | 6/38 [00:04<00:14,  2.19it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:14,  2.12it/s]Evaluation:  21%|██        | 8/38 [00:05<00:12,  2.40it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:09,  3.03it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:06,  4.09it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.45it/s]Evaluation:  39%|███▉      | 15/38 [00:06<00:03,  5.82it/s]Evaluation:  42%|████▏     | 16/38 [00:06<00:03,  6.22it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:03,  6.08it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.21it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  6.82it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:02,  8.43it/s]Evaluation:  58%|█████▊    | 22/38 [00:07<00:02,  6.31it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  4.90it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  4.74it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  4.96it/s]Evaluation:  74%|███████▎  | 28/38 [00:08<00:01,  6.60it/s]Evaluation:  76%|███████▋  | 29/38 [00:08<00:01,  6.81it/s]Evaluation:  79%|███████▉  | 30/38 [00:08<00:01,  6.26it/s]Evaluation:  82%|████████▏ | 31/38 [00:09<00:02,  3.12it/s]Evaluation:  84%|████████▍ | 32/38 [00:09<00:01,  3.71it/s]Evaluation:  89%|████████▉ | 34/38 [00:09<00:00,  4.57it/s]Evaluation:  92%|█████████▏| 35/38 [00:09<00:00,  5.14it/s]Evaluation:  97%|█████████▋| 37/38 [00:10<00:00,  5.04it/s]Evaluation: 100%|██████████| 38/38 [00:10<00:00,  5.02it/s]Evaluation: 100%|██████████| 38/38 [00:10<00:00,  3.65it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_58', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:28:31 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:28:31 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:28:31 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:12,  3.57s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:34,  1.02it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:17,  1.85it/s]Evaluation:  16%|█▌        | 6/38 [00:04<00:13,  2.29it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:14,  2.18it/s]Evaluation:  21%|██        | 8/38 [00:04<00:11,  2.57it/s]Evaluation:  24%|██▎       | 9/38 [00:04<00:08,  3.23it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:09,  3.08it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.73it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.77it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.51it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  7.04it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:02,  7.47it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:02,  7.42it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  7.26it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  9.25it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.48it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  6.85it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:01,  6.53it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:01,  6.33it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  8.12it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.38it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.15it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  4.05it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.79it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.75it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  7.12it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  6.10it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.95it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.04it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_53', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:28:51 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:28:51 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:28:51 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:10,  3.62s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:57,  1.64s/it]Evaluation:   8%|▊         | 3/37 [00:04<00:33,  1.03it/s]Evaluation:  11%|█         | 4/37 [00:04<00:21,  1.55it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.85it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.85it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.48it/s]Evaluation:  24%|██▍       | 9/37 [00:05<00:06,  4.00it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  4.07it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.77it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:04,  5.28it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:08,  2.93it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:07,  3.10it/s]Evaluation:  46%|████▌     | 17/37 [00:06<00:03,  6.04it/s]Evaluation:  54%|█████▍    | 20/37 [00:06<00:01,  9.11it/s]Evaluation:  59%|█████▉    | 22/37 [00:06<00:01, 10.17it/s]Evaluation:  65%|██████▍   | 24/37 [00:07<00:01,  6.74it/s]Evaluation:  70%|███████   | 26/37 [00:07<00:01,  8.20it/s]Evaluation:  76%|███████▌  | 28/37 [00:07<00:01,  6.67it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.70it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.77it/s]Evaluation:  92%|█████████▏| 34/37 [00:09<00:00,  5.45it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  5.73it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  6.01it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.58it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.88it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_67', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:29:11 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:29:11 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:29:11 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:07,  3.46s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:33,  1.04it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:17,  1.88it/s]Evaluation:  16%|█▌        | 6/38 [00:04<00:14,  2.27it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:14,  2.18it/s]Evaluation:  21%|██        | 8/38 [00:04<00:12,  2.44it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:09,  3.05it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:06,  4.20it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.57it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.18it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.68it/s]Evaluation:  45%|████▍     | 17/38 [00:06<00:02,  7.09it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.51it/s]Evaluation:  53%|█████▎    | 20/38 [00:06<00:02,  8.49it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.50it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  6.77it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  6.43it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:01,  6.26it/s]Evaluation:  71%|███████   | 27/38 [00:07<00:01,  6.53it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.69it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.41it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.80it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.50it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  4.92it/s]Evaluation:  95%|█████████▍| 36/38 [00:09<00:00,  6.61it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.43it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.21it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  3.93it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_4', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:29:32 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:29:32 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:29:32 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:00,  3.27s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.10it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.98it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.40it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:14,  2.11it/s]Evaluation:  21%|██        | 8/38 [00:04<00:12,  2.43it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:09,  3.04it/s]Evaluation:  29%|██▉       | 11/38 [00:05<00:07,  3.56it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.66it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.08it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:03,  6.67it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:02,  6.84it/s]Evaluation:  53%|█████▎    | 20/38 [00:06<00:02,  8.42it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.04it/s]Evaluation:  63%|██████▎   | 24/38 [00:07<00:02,  5.01it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  4.85it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.15it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  6.61it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  6.46it/s]Evaluation:  79%|███████▉  | 30/38 [00:08<00:01,  6.54it/s]Evaluation:  82%|████████▏ | 31/38 [00:09<00:02,  2.78it/s]Evaluation:  84%|████████▍ | 32/38 [00:09<00:01,  3.39it/s]Evaluation:  89%|████████▉ | 34/38 [00:09<00:00,  4.04it/s]Evaluation:  95%|█████████▍| 36/38 [00:09<00:00,  5.57it/s]Evaluation:  97%|█████████▋| 37/38 [00:10<00:00,  4.72it/s]Evaluation: 100%|██████████| 38/38 [00:10<00:00,  4.54it/s]Evaluation: 100%|██████████| 38/38 [00:10<00:00,  3.68it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_60', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:29:53 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:29:53 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:29:53 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:03,  3.42s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:53,  1.54s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:31,  1.09it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.62it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.91it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:10,  2.75it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.79it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  3.90it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:05,  4.53it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:08,  2.78it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:07,  2.96it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.44it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:02,  7.29it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  8.98it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:01,  7.06it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.45it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.89it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  6.82it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.92it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.90it/s]Evaluation:  92%|█████████▏| 34/37 [00:09<00:00,  5.76it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  5.63it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.97it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  6.53it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.87it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_11', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:30:14 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:30:14 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:30:14 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:01,  3.38s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:54,  1.55s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:32,  1.06it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.61it/s]Evaluation:  14%|█▎        | 5/37 [00:04<00:13,  2.31it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  3.05it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.66it/s]Evaluation:  22%|██▏       | 8/37 [00:04<00:08,  3.44it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.89it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.59it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  4.14it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.92it/s]Evaluation:  32%|███▏      | 12/37 [00:06<00:12,  1.95it/s]
Traceback (most recent call last):
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/main.py", line 331, in <module>
    run_eval()
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/main.py", line 272, in run_eval
    return training.run_eval(**eval_args)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 1251, in run_eval
    metrics_to_save, outputs_to_save = run_eval_epoch(valid_loader, runner, metrics, metric_functions,
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 550, in run_eval_epoch
    loss, metrics, outputs = runner.forward(batch, return_outputs=True) # type: ignore
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/training.py", line 106, in forward
    outputs = self.model(**batch)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 597, in forward
    encoder_outputs = self.encoder(embedding_output,
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 482, in forward
    layer_outputs = layer_module(hidden_states, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 420, in forward
    attention_outputs = self.attention(hidden_states, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 370, in forward
    self_outputs = self.self(input_tensor, attention_mask, cross_hidden_states, cross_attention_mask)
  File "/scratch/user/zshuying/.conda/envs/ProLMEnv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/user/zshuying/ppi_mutation/ProteinEncoder-LM-main/scripts/models/modeling_pt_bert.py", line 290, in forward
    attention_scores = attention_scores / math.sqrt(self.attention_head_size)
RuntimeError: CUDA out of memory. Tried to allocate 7.69 GiB (GPU 0; 39.45 GiB total capacity; 32.00 GiB already allocated; 5.96 GiB free; 32.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: g034: task 0: Exited with exit code 1
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_10', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:30:29 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:30:29 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:30:29 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:03,  3.34s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:32,  1.08it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.96it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.42it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:12,  2.44it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.85it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:07,  3.54it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.94it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.26it/s]Evaluation:  37%|███▋      | 14/38 [00:05<00:04,  5.72it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  7.05it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.26it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  7.30it/s]Evaluation:  50%|█████     | 19/38 [00:05<00:02,  7.10it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  8.94it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.65it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:02,  5.52it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:02,  5.69it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.76it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  7.59it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.18it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.12it/s]Evaluation:  82%|████████▏ | 31/38 [00:07<00:01,  5.17it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  5.39it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  6.24it/s]Evaluation:  95%|█████████▍| 36/38 [00:08<00:00,  7.98it/s]Evaluation:  97%|█████████▋| 37/38 [00:08<00:00,  6.12it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  5.97it/s]Evaluation: 100%|██████████| 38/38 [00:08<00:00,  4.25it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_51', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:30:48 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:30:48 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:30:48 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:03,  3.34s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:32,  1.08it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:17,  1.93it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.32it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:13,  2.33it/s]Evaluation:  21%|██        | 8/38 [00:04<00:11,  2.57it/s]Evaluation:  26%|██▋       | 10/38 [00:05<00:08,  3.31it/s]Evaluation:  32%|███▏      | 12/38 [00:05<00:05,  4.62it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:05,  4.57it/s]Evaluation:  39%|███▉      | 15/38 [00:05<00:03,  6.01it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.35it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:03,  6.15it/s]Evaluation:  47%|████▋     | 18/38 [00:06<00:03,  6.21it/s]Evaluation:  50%|█████     | 19/38 [00:06<00:02,  6.81it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:01,  8.59it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  6.42it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:02,  6.92it/s]Evaluation:  66%|██████▌   | 25/38 [00:07<00:02,  6.41it/s]Evaluation:  68%|██████▊   | 26/38 [00:07<00:02,  5.72it/s]Evaluation:  71%|███████   | 27/38 [00:07<00:01,  6.42it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.54it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  7.10it/s]Evaluation:  82%|████████▏ | 31/38 [00:08<00:01,  3.83it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.29it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  4.73it/s]Evaluation:  92%|█████████▏| 35/38 [00:09<00:00,  5.36it/s]Evaluation:  97%|█████████▋| 37/38 [00:09<00:00,  5.40it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.30it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  3.95it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_8', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:31:09 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:31:09 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:31:09 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<02:02,  3.39s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:54,  1.55s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:32,  1.05it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.62it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  2.90it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.65it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.72it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:07,  3.78it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  4.08it/s]Evaluation:  35%|███▌      | 13/37 [00:05<00:05,  4.26it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:05,  4.09it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:03,  5.84it/s]Evaluation:  51%|█████▏    | 19/37 [00:06<00:01,  9.12it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01, 10.83it/s]Evaluation:  62%|██████▏   | 23/37 [00:06<00:01,  7.30it/s]Evaluation:  68%|██████▊   | 25/37 [00:07<00:01,  7.40it/s]Evaluation:  73%|███████▎  | 27/37 [00:07<00:01,  7.70it/s]Evaluation:  78%|███████▊  | 29/37 [00:07<00:01,  6.44it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.27it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.81it/s]Evaluation:  92%|█████████▏| 34/37 [00:08<00:00,  4.92it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  5.19it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  5.11it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  5.64it/s]Evaluation: 100%|██████████| 37/37 [00:09<00:00,  3.92it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_34', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:31:29 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:31:29 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:31:29 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/37 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/37 [00:03<01:57,  3.27s/it]Evaluation:   5%|▌         | 2/37 [00:03<00:52,  1.49s/it]Evaluation:   8%|▊         | 3/37 [00:03<00:30,  1.11it/s]Evaluation:  11%|█         | 4/37 [00:03<00:20,  1.64it/s]Evaluation:  14%|█▎        | 5/37 [00:03<00:13,  2.33it/s]Evaluation:  16%|█▌        | 6/37 [00:04<00:10,  3.08it/s]Evaluation:  19%|█▉        | 7/37 [00:04<00:11,  2.70it/s]Evaluation:  24%|██▍       | 9/37 [00:04<00:07,  3.96it/s]Evaluation:  27%|██▋       | 10/37 [00:05<00:06,  3.96it/s]Evaluation:  30%|██▉       | 11/37 [00:05<00:06,  4.22it/s]Evaluation:  32%|███▏      | 12/37 [00:05<00:05,  4.90it/s]Evaluation:  35%|███▌      | 13/37 [00:06<00:09,  2.58it/s]Evaluation:  38%|███▊      | 14/37 [00:06<00:08,  2.86it/s]Evaluation:  43%|████▎     | 16/37 [00:06<00:04,  4.47it/s]Evaluation:  49%|████▊     | 18/37 [00:06<00:03,  6.11it/s]Evaluation:  57%|█████▋    | 21/37 [00:06<00:01,  8.83it/s]Evaluation:  62%|██████▏   | 23/37 [00:07<00:02,  6.51it/s]Evaluation:  65%|██████▍   | 24/37 [00:07<00:02,  6.26it/s]Evaluation:  70%|███████   | 26/37 [00:07<00:01,  7.69it/s]Evaluation:  76%|███████▌  | 28/37 [00:08<00:01,  6.29it/s]Evaluation:  78%|███████▊  | 29/37 [00:08<00:01,  6.45it/s]Evaluation:  81%|████████  | 30/37 [00:08<00:01,  6.53it/s]Evaluation:  84%|████████▍ | 31/37 [00:08<00:01,  5.51it/s]Evaluation:  89%|████████▉ | 33/37 [00:08<00:00,  7.59it/s]Evaluation:  92%|█████████▏| 34/37 [00:09<00:00,  3.55it/s]Evaluation:  95%|█████████▍| 35/37 [00:09<00:00,  3.97it/s]Evaluation:  97%|█████████▋| 36/37 [00:09<00:00,  4.42it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  4.96it/s]Evaluation: 100%|██████████| 37/37 [00:10<00:00,  3.64it/s]
srun: Job 6840125 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for job 6840125
ProLMEnv
task:['embed', 'embed_seq', 'masked_language_modeling', 'language_modeling', 'fluorescence', 'stability', 'remote_homology', 'contact_prediction', 'secondary_structure', 'trrosetta', 'penalize_nonContact_attention', 'promote_contact_attention', 'contact_ce_attention', 'contact_ce_attention_weightnor', 'esm_eval', 'mutation_fitness_supervise_mutagenesis', 'mutation_fitness_UNsupervise_mutagenesis', 'multitask_fitness_UNsupervise_mutagenesis', 'mutation_fitness_UNsupervise_scanning', 'mutation_fitness_UNsupervise_CAGI', 'antibody_mlm_seqConcate', 'antibody_embed_seqConcate', 'antibody_mlm_seqIndiv', 'antibody_embed_seqIndiv', 'seq_structure_multi_task']
>>task:embed - models:['transformer']
>>task:embed_seq - models:['transformer']
>>task:masked_language_modeling - models:['transformer']
>>task:language_modeling - models:[]
>>task:fluorescence - models:['transformer']
>>task:stability - models:['transformer']
>>task:remote_homology - models:['transformer']
>>task:contact_prediction - models:['transformer']
>>task:secondary_structure - models:['transformer']
>>task:trrosetta - models:[]
>>task:penalize_nonContact_attention - models:['transformer']
>>task:promote_contact_attention - models:['transformer']
>>task:contact_ce_attention - models:['transformer']
>>task:contact_ce_attention_weightnor - models:['transformer']
>>task:esm_eval - models:[]
>>task:mutation_fitness_supervise_mutagenesis - models:['transformer']
>>task:mutation_fitness_UNsupervise_mutagenesis - models:['transformer']
>>task:multitask_fitness_UNsupervise_mutagenesis - models:['lm_mp']
>>task:mutation_fitness_UNsupervise_scanning - models:['transformer']
>>task:mutation_fitness_UNsupervise_CAGI - models:['transformer']
>>task:antibody_mlm_seqConcate - models:['transformer']
>>task:antibody_embed_seqConcate - models:['transformer']
>>task:antibody_mlm_seqIndiv - models:['transformer']
>>task:antibody_embed_seqIndiv - models:['transformer']
>>task:seq_structure_multi_task - models:['lm_mp']
metric:['mse', 'fitness_assess_supervise', 'mae', 'spearmanr', 'accuracy', 'accuracy_subClass_AB', 'accuracy_top3', 'accuracy_top3_subClass_AB', 'accuracy_top5', 'accuracy_top5_subClass_AB', 'accuracy_top10', 'accuracy_top10_subClass_AB', 'perplexity', 'perplexity_subClass_AB', 'contact_background_prec', 'all_pred_distribution', 'contact_precision', 'train_logisticRegression_layerwise', 'train_logisticRegression_layersupervise', 'train_logisticRegression', 'test_logisticRegression', 'test_logisticRegression_layerwise', 'test_logisticRegression_layersupervise', 'logisContact_esm', 'fitness_unsupervise_CAGI', 'fitness_unsupervise_scanning', 'fitness_unsupervise_mutagenesis', 'multitask_seq_struct_eval', 'multitask_unsupervise_mutagenesis', 'embed_antibody_internal', 'embed_antibody', 'save_embedding_internal', 'save_embedding']
>>>run_type: run_eval
_>main/run_eval, eval_args:{'model_type': 'transformer', 'task': 'embed_seq', 'from_pretrained': '/scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models', 'pretrained_epoch': None, 'split': 'batch150_18', 'batch_size': 4, 'model_config_file': None, 'extra_config_file': None, 'data_dir': '/scratch/user/zshuying/ppi_mutation/data/single_protein_seq/', 'eval_save_dir': None, 'data_format': 'lmdb', 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'tokenizer': 'pfam', 'num_workers': 8, 'debug': False, 'metrics': ['save_embedding'], 'log_level': 20, 'mutgsis_set': None, 'mlm_mask_stragy': 'vanilla', 'embed_modelNm': 'rp15_pretrain_1_models', 'neighbor_strategy': 'knn', 'knn_value': 20, 'dist_cutoff': 12.0}
23/01/18 17:31:51 - INFO - models.modeling_utils -   loading configuration file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/config.json
23/01/18 17:31:51 - INFO - models.modeling_utils -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "attention_type": "softmax",
  "finetuning_task": null,
  "gamma": 0.0,
  "gradient_checkpointing": false,
  "head_selector": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "lamda_ce": 1.0,
  "lamda_contact": 1.0,
  "lamda_l1": 0.1,
  "lamda_mlm": 1.0,
  "lamda_nonContact": 1.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 8096,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": -1,
  "output_attentions": true,
  "output_hidden_states": true,
  "performer_attention_config": null,
  "subClass_dropoutProb": 0.1,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28,
  "weight_l_con": 1.0,
  "weight_l_non": 1.0,
  "weight_long": 1.0,
  "weight_m_con": 1.0,
  "weight_m_non": 1.0,
  "weight_medium": 1.0,
  "weight_s_con": 1.0,
  "weight_s_non": 1.0,
  "weight_short": 1.0,
  "weight_subClassLoss": 0.0
}

23/01/18 17:31:51 - INFO - models.modeling_utils -   loading weights file /scratch/user/zshuying/ppi_mutation/trained_models/rp15_pretrain_1_models/pytorch_model.bin
Evaluation:   0%|          | 0/38 [00:00<?, ?it/s]Evaluation:   3%|▎         | 1/38 [00:03<02:00,  3.25s/it]Evaluation:   8%|▊         | 3/38 [00:03<00:31,  1.11it/s]Evaluation:  13%|█▎        | 5/38 [00:03<00:16,  1.99it/s]Evaluation:  16%|█▌        | 6/38 [00:03<00:13,  2.36it/s]Evaluation:  18%|█▊        | 7/38 [00:04<00:12,  2.42it/s]Evaluation:  21%|██        | 8/38 [00:04<00:10,  2.83it/s]Evaluation:  26%|██▋       | 10/38 [00:04<00:07,  3.56it/s]Evaluation:  32%|███▏      | 12/38 [00:04<00:05,  4.97it/s]Evaluation:  34%|███▍      | 13/38 [00:05<00:04,  5.21it/s]Evaluation:  37%|███▋      | 14/38 [00:05<00:04,  5.64it/s]Evaluation:  42%|████▏     | 16/38 [00:05<00:03,  6.94it/s]Evaluation:  45%|████▍     | 17/38 [00:05<00:02,  7.15it/s]Evaluation:  47%|████▋     | 18/38 [00:05<00:02,  7.00it/s]Evaluation:  50%|█████     | 19/38 [00:05<00:02,  6.80it/s]Evaluation:  55%|█████▌    | 21/38 [00:06<00:02,  8.45it/s]Evaluation:  58%|█████▊    | 22/38 [00:06<00:02,  7.26it/s]Evaluation:  63%|██████▎   | 24/38 [00:06<00:01,  8.21it/s]Evaluation:  66%|██████▌   | 25/38 [00:06<00:01,  6.77it/s]Evaluation:  68%|██████▊   | 26/38 [00:06<00:01,  6.55it/s]Evaluation:  74%|███████▎  | 28/38 [00:07<00:01,  8.22it/s]Evaluation:  76%|███████▋  | 29/38 [00:07<00:01,  7.17it/s]Evaluation:  79%|███████▉  | 30/38 [00:07<00:01,  6.97it/s]Evaluation:  82%|████████▏ | 31/38 [00:07<00:01,  3.81it/s]Evaluation:  84%|████████▍ | 32/38 [00:08<00:01,  4.33it/s]Evaluation:  89%|████████▉ | 34/38 [00:08<00:00,  5.27it/s]Evaluation:  92%|█████████▏| 35/38 [00:08<00:00,  5.83it/s]Evaluation:  97%|█████████▋| 37/38 [00:08<00:00,  5.94it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  5.80it/s]Evaluation: 100%|██████████| 38/38 [00:09<00:00,  4.19it/s]
