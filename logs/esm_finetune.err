GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name      | Type            | Params
----------------------------------------------
0 | esm_model | ESM2            | 33.5 M
1 | proj      | Sequential      | 1.4 K 
2 | auroc     | MulticlassAUROC | 0     
----------------------------------------------
8.6 M     Trainable params
24.9 M    Non-trainable params
33.5 M    Total params
134.011   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/lightning/pytorch/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score
  warnings.warn(*args, **kwargs)
Metric val_loss improved. New best score: 0.835
Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.820
Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.812
Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.804
Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.799
Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.792
Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.787
Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.786
Monitored metric val_loss did not improve in the last 5 records. Best score: 0.786. Signaling Trainer to stop.
You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /scratch/user/zshuying/ppi_mutation/logs/esm_finetune/esm2_t12_35M_UR50D/lr4-05_unfreeze6/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name      | Type            | Params
----------------------------------------------
0 | esm_model | ESM2            | 33.5 M
1 | proj      | Sequential      | 1.4 K 
2 | auroc     | MulticlassAUROC | 0     
----------------------------------------------
8.6 M     Trainable params
24.9 M    Non-trainable params
33.5 M    Total params
134.011   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/lightning/pytorch/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name      | Type            | Params
----------------------------------------------
0 | esm_model | ESM2            | 33.5 M
1 | proj      | Sequential      | 1.4 K 
2 | auroc     | MulticlassAUROC | 0     
----------------------------------------------
8.6 M     Trainable params
24.9 M    Non-trainable params
33.5 M    Total params
134.011   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/scratch/user/zshuying/.conda/envs/yuning/lib/python3.9/site-packages/lightning/pytorch/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
